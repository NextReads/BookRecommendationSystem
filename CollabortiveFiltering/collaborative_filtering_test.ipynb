{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "# import AgglomerativeClustering from sklearn\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset\"\n",
    "top_percent = 0.4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items   I1   I2   I3   I4   I5\n",
      "Users                         \n",
      "U1     1.0  4.0  5.0  3.0  2.0\n",
      "U2     2.0  3.0  4.0  5.0  1.0\n",
      "U3     NaN  4.0  3.0  NaN  1.0\n",
      "U4     1.0  2.0  3.0  4.0  5.0\n",
      "U5     5.0  4.0  3.0  2.0  1.0\n",
      "Items   I1        I2        I3   I4        I5\n",
      "Users                                        \n",
      "U1    -2.0  1.000000  2.000000  0.0 -1.000000\n",
      "U2    -1.0  0.000000  1.000000  2.0 -2.000000\n",
      "U3     NaN  1.333333  0.333333  NaN -1.666667\n",
      "U4    -2.0 -1.000000  0.000000  1.0  2.000000\n",
      "U5     2.0  1.000000  0.000000 -1.0 -2.000000\n"
     ]
    }
   ],
   "source": [
    "# Creating MxN matrix where M is the number of users and N is the number of books\n",
    "# an Example of the representation of the matrix is shown below\n",
    "#       Items  I1        I2        I3      I4      I5\n",
    "# Users\n",
    "# U1           1.0       4.0       5.0     3.0     2.0\n",
    "# U2           2.0       3.0       4.0     5.0     1.0\n",
    "# U3           0.0       4.0       3.0     0.0     1.0\n",
    "# U4           1.0       2.0       3.0     4.0     5.0\n",
    "# U5           5.0       4.0       3.0     2.0     1.0\n",
    "\n",
    "dataframe = {\"Users\": [\"U1\", \"U1\", \"U1\", \"U1\", \"U1\",\n",
    "                        \"U2\", \"U2\", \"U2\", \"U2\", \"U2\", \n",
    "                        \"U3\", \"U3\", \"U3\", \"U3\", \"U3\", \n",
    "                        \"U4\", \"U4\", \"U4\", \"U4\", \"U4\", \n",
    "                        \"U5\", \"U5\", \"U5\", \"U5\", \"U5\"], \n",
    "              \"Items\": [\"I1\", \"I2\", \"I3\", \"I4\", \"I5\",\n",
    "                        \"I1\", \"I2\", \"I3\", \"I4\", \"I5\",\n",
    "                        \"I1\", \"I2\", \"I3\", \"I4\", \"I5\",\n",
    "                        \"I1\", \"I2\", \"I3\", \"I4\", \"I5\",\n",
    "                        \"I1\", \"I2\", \"I3\", \"I4\", \"I5\"],\n",
    "             \"Ratings\": [1.0, 4.0, 5.0, 3.0, 2.0,\n",
    "                        2.0, 3.0, 4.0, 5.0, 1.0,\n",
    "                        np.nan, 4.0, 3.0, np.nan, 1.0,\n",
    "                        1.0, 2.0, 3.0, 4.0, 5.0,\n",
    "                        5.0, 4.0, 3.0, 2.0, 1.0]}\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dataframe)\n",
    "\n",
    "# must include the Nan values in the pivot table\n",
    "rating_matrix = df.pivot(index=\"Users\", columns=\"Items\", values=\"Ratings\")\n",
    "print(rating_matrix)\n",
    "\n",
    "mean_centered_matrix = rating_matrix.sub(rating_matrix.mean(axis=1), axis=0)\n",
    "print(mean_centered_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pearson_similarity_matrix = rating_matrix.copy()\n",
    "\n",
    "# use corr function to calculate pearson correlation between users (columns)\n",
    "user_pearson_similarity_matrix = user_pearson_similarity_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "user_pearson_similarity_matrix = user_pearson_similarity_matrix.T.corr(method=\"pearson\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def similar_users(userID: str, top_percent: int, threshold: float = 0.2):\n",
    "    index = rating_matrix.index.get_loc(userID)\n",
    "    row_rating = user_pearson_similarity_matrix.iloc[index]\n",
    "    row_rating.sort_values(ascending=False, inplace=True)\n",
    "    top_users = round(len(user_pearson_similarity_matrix) * top_percent)\n",
    "    user_list = list(row_rating.index[1:top_users+1])\n",
    "    # remove users with similarity less than threshold\n",
    "    user_list = [user for user in user_list if row_rating[user] > threshold]\n",
    "    return user_list\n",
    "\n",
    "def find_not_rated_books(userID: str):\n",
    "    not_rated_books = rating_matrix.loc[userID][rating_matrix.loc[userID].isnull()].index\n",
    "    return list(not_rated_books)\n",
    "\n",
    "\n",
    "# this function predicts the rating of the missing values in the rating matrix for a given user given a list of similar users\n",
    "def predict_rating_user(userID: str , userIDs: list):\n",
    "    # get the not rated books by the user\n",
    "    not_rated_books = find_not_rated_books(userID)\n",
    "    # dictionary to store the predicted rating for each book\n",
    "    prediction_dict = {}\n",
    "    for book in not_rated_books:\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for user in userIDs:\n",
    "            if not np.isnan(rating_matrix.loc[user][book]):\n",
    "                numerator += user_pearson_similarity_matrix.loc[userID][user] * mean_centered_matrix.loc[user][book]\n",
    "                denominator += user_pearson_similarity_matrix.loc[userID][user]\n",
    "        if denominator == 0:\n",
    "            prediction_dict[book] = 0\n",
    "        else:\n",
    "            prediction_dict[book] = numerator / denominator + rating_matrix.loc[userID].mean()\n",
    "    \n",
    "    # sort the dictionary by the predicted rating in descending order\n",
    "    prediction_dict = {i: v for i, v in sorted(prediction_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return prediction_dict\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-based collaborative filtering test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended books for user are: (Item: Rating Prediction)\n",
      "{'I1': 2.9066666666666663, 'I4': 2.1066666666666665}\n"
     ]
    }
   ],
   "source": [
    "top_users_percent = 0.35\n",
    "mylist = similar_users(\"U3\", top_users_percent)\n",
    "user_based_prediction = predict_rating_user(\"U3\", mylist)\n",
    "print(\"recommended books for user are: (Item: Rating Prediction)\")\n",
    "print(user_based_prediction)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items        I1        I2        I3        I4        I5\n",
      "Items                                                  \n",
      "I1     1.000000  0.508223 -0.508223 -0.614286 -0.583212\n",
      "I2     0.508223  1.000000  0.250000 -0.711512 -0.806872\n",
      "I3    -0.508223  0.250000  1.000000  0.237171 -0.161374\n",
      "I4    -0.614286 -0.711512  0.237171  1.000000  0.285774\n",
      "I5    -0.583212 -0.806872 -0.161374  0.285774  1.000000\n"
     ]
    }
   ],
   "source": [
    "item_pearson_similarity_matrix = rating_matrix.copy()\n",
    "# use corr function to calculate pearson correlation between users (columns)\n",
    "item_pearson_similarity_matrix = item_pearson_similarity_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "item_pearson_similarity_matrix = item_pearson_similarity_matrix.corr(method=\"pearson\")\n",
    "print(item_pearson_similarity_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_items(itemID: str, top_items_number: int = len(rating_matrix.columns), threshold: float = 0.2):\n",
    "    index = rating_matrix.columns.get_loc(itemID)\n",
    "    coloumn_rating = item_pearson_similarity_matrix.iloc[index]\n",
    "    coloumn_rating.sort_values(ascending=False, inplace=True)\n",
    "    top_items = min(len(item_pearson_similarity_matrix), top_items_number)\n",
    "    item_list = list(coloumn_rating.index[1:top_items+1])\n",
    "    # remove items with similarity less than threshold\n",
    "    item_list = [item for item in item_list if coloumn_rating[item] > threshold]\n",
    "    return item_list\n",
    "\n",
    "\n",
    "\n",
    "def predict_rating_item(userID: str):\n",
    "    not_rated_books = find_not_rated_books(userID)\n",
    "    # dictionary to store the predicted rating for each book\n",
    "    prediction_dict = {}\n",
    "    top_items_number = round(sqrt(len(rating_matrix.columns)))\n",
    "\n",
    "    for book in not_rated_books:\n",
    "        similar_books = similar_items(book, top_items_number)\n",
    "        # print(\"similar books for book {} are:\".format(book))\n",
    "        # print(similar_books)\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for item in similar_books:\n",
    "            if not np.isnan(rating_matrix.loc[userID][item]):\n",
    "                numerator += item_pearson_similarity_matrix.loc[book][item] * rating_matrix.loc[userID][item]\n",
    "                denominator += item_pearson_similarity_matrix.loc[book][item]\n",
    "                # print(\"denominator: {}\".format(denominator))\n",
    "        if denominator == 0:\n",
    "            prediction_dict[book] = 0\n",
    "        else:\n",
    "            prediction_dict[book] = numerator / denominator\n",
    "        # print(\"----------------------------------------\")\n",
    "    # sort the dictionary by the predicted rating in descending order\n",
    "    prediction_dict = {i: v for i, v in sorted(prediction_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return prediction_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item-based collaborative filtering test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I2']\n",
      "{'I1': 4.0, 'I4': 1.9070590341216882}\n"
     ]
    }
   ],
   "source": [
    "# case item searched, with no clue who the user is\n",
    "item_prediction = similar_items(\"I1\")\n",
    "print(item_prediction)\n",
    "\n",
    "# case user logged in\n",
    "item_based_prediction = predict_rating_item(\"U3\")\n",
    "print(item_based_prediction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final predictions & statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user mean: 2.6666666666666665\n",
      "{'I1': 3.453333333333333, 'I4': 2.0068628503941772}\n",
      "RMSE for user based CF: 0.4308131845707603\n",
      "RMSE for item based CF: 1.0850763874489124\n",
      "RMSE for average prediction: 0.7260115427499019\n"
     ]
    }
   ],
   "source": [
    "user_mean = rating_matrix.loc[\"U3\"].mean()\n",
    "print(\"user mean: {}\".format(user_mean))\n",
    "\n",
    "## calculating average prediction from item and user CF\n",
    "average_prediction = {}\n",
    "for item in item_based_prediction:\n",
    "    average_prediction[item] = (item_based_prediction[item] + user_based_prediction[item]) / 2\n",
    "\n",
    "print(average_prediction)\n",
    "\n",
    "# calculating the RMSE\n",
    "def rmse(prediction_dict: dict, user_mean: float):\n",
    "    rmse = 0\n",
    "    for item in prediction_dict:\n",
    "        rmse += (prediction_dict[item] - user_mean) ** 2\n",
    "    rmse = sqrt(rmse / len(prediction_dict))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "print(\"RMSE for user based CF: {}\".format(rmse(user_based_prediction, user_mean)))\n",
    "print(\"RMSE for item based CF: {}\".format(rmse(item_based_prediction, user_mean)))\n",
    "print(\"RMSE for average prediction: {}\".format(rmse(average_prediction, user_mean)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81ebf64e9fb32fa207ff8ddb88fe835428ac222285ffabe99259f0a6550c9f80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
